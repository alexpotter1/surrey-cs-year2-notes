# Artificial Intelligence (COM2028)
Note: This document includes inline LaTeX, which won't display on GitHub. Install Typora to view this.

## Image Processing

* Algorithmic processing of raw information from sensors and visual systems (cameras)
* Understand how sensory stimuli are created by the world in general

### Flow of processing

* Move from specifics to generics
* Captured data -> Pre-processing (enhancement) -> Feature Extraction -> Object classification (specific) -> Image classification (general)

### Image analysis techniques

* Template matching
* Pattern recognition with feature extraction
* Edge detection

![Image](https://qph.ec.quoracdn.net/main-qimg-fe87feb1ec474e5b0851b0616d49e50e-c)

### How to manipulate images?

* **Brightness enhancement**
  * Scale all values by a constant
  * $$g(x,y) = f(x,y) + k$$
* **Contrast enhancement**
  * Scale all values again by a constant
  * $$g(x,y) = af(x,y)$$
* **Average of two images**
* **Spatial resolution**
  * Measure of how closely lines can be resolved in an image
  * *clarity of image*
* **Amplitude resolution**
  * How many different shades of grey or colour
  * 16-bit, 8-bit, 4-bit colour images etc

### Objectives of image processing

* Enhance features that are useful
* Reduce noise
* Obtain **salient features** of image content (key representations)

## Image transforms

* Point transforms
* Local transforms
* Global transforms

### Point transforms

* Manipulating individual pixel values
  * Brightness/contrast enhancement
* Histogram manipulation
* Image magnification

### Mapping

* Linear
* Non-linear
  * **Logarithmic mapping**: enhance darker regions of image, at the expense of lighter region details
  * **Exponential mapping**: enhance lighter regions of image, at the expense of darker region details
* Can map ranges of pixels onto a new range:
  * $$\frac{g(x,y) - g_1}{f(x,y) - f_1} = \frac{g_2 - g_1}{f_2 - f_1}$$
  * $$g(x,y) = g_1 + (\frac{g_2-g_1}{f_2-f_1})(f(x,y) - f_1)$$

### Image histogram

* Measure frequency of the occurrence of each grey/colour value

  ```python
  pixels_x = []
  pixels_y = []
  histogram = []
  i = 0
  for all grey in pixels:
      histogram[i] = 0
      i += 1
  for (x,y) in enumerate(zip(pixels_x, pixels_y)):
      histogram[f(x,y)] += 1
  ```



* **Cumulative histogram**: Records **cumulative frequency distribution** of grey levels in an image

  * Is a mapping that counts the cumulative number of pixels in all of the bins up to a specified bin number
  * Defined by *cumulative histogram* $H_k = \sum_{j=0}^{k}h_j$

## Feature Extraction and Segmentation

A computer needs a training algorithm to be able to recognise objects in images

#### Gestalt Laws of Perception

* Gestalt Law of Similarity
* Gestalt Law of Continuation
* Gestalt Law of Closure

#### SIFT

Stands for **Scale Invariant Feature Transform**

* Converting an image into feature vectors that were invariant to scale, translation and rotation operations
* Can be used as a *descriptor* of an image

#### ImageNet

Database of categorised images

### *META: Merge Week4 on intel-sc*

## Neural Networks

### Brains vs Artificial Neural Networks

* A brain can be considered a **highly complex**, **non-linear** and **parallel information-processing system**.

* Learning is a fundamental and essential characteristic of biological neural networks. The ease with which they can learn led to attempts to emulate a biological neural network using computers.

* In the brain, each neuron has a very simple structure. However, since there are many of them, collectively they consitute a tremendously powerful way to perform processing.
  * Each neuron consists of a cell body (**soma**), a number of fibres (**dendrites**) and a single long fibre (**axon**), covered in a **myelin sheath** to add electrical insulation.

  * A neuron only fires if its input signal exceeds a certain amount (an electrical voltage threshold) in a short time period.

  * The spikes travelling along the axon of the pre-synaptic neuron trigger the release of neurotransmitter chemicals at the synapse.

    * Synapses vary in strength
    * Good connections allow for a strong signal
    * Poor connections allow only a weak signal
    * Synapses can be *excitatory* or *inhibitory*.

  * The neurotransmitters cause **excitation** or **inhibition** in the *dendrite* of the post-synaptic neuron.

  * The integration of *excitatory* and *inhibitory* signals may produce spikes in the post-synaptic neuron.

  * The contribution of the signals depends on the strength of the synaptic connection.

  * ![neuron](https://upload.wikimedia.org/wikipedia/commons/thumb/3/30/SynapseSchematic_en.svg/800px-SynapseSchematic_en.svg.png)

  * Each neuron has an **activation function**, that defines a threshold at which the neuron fires if the signal is greater than or equal to.

    * This is a **step function**, and is **sigmoid** ($$\frac{1}{1+e^{-x}})$$

  * ![neuron-artificial](https://isaacchanghau.github.io/images/deeplearning/activationfunction/intro.png)

    â€‹

* Hence, comparisons can be made between the nature of the brain and artificial neural networks:

  * | Biological neural networks | Artificial neural networks |
    | :------------------------: | :------------------------: |
    |      Soma (cell body)      |       Neuron (node)        |
    |         Dendrites          |           Inputs           |
    |            Axon            |           Output           |
    |          Synapse           |           Weight           |


## Artificial Neural Networks

* Can be classified into two main constituents:
  * Supervised (**known classes**)
  * Unsupervised (**unknown classes**)

### Supervised learning

* Also known as *active learning*

* Learning with an external *"teacher"* or supervisor

  * The *teacher* presents a training set, with inputs and *known* (desired) outputs to the network
  * Most popular supervised neural network is the **multilayer perceptron**, which is trained using **back-propagation**.

* **Multilayer perceptron**:

  * Also known as a *"vanilla"* neural network 
  * Used where classes are known beforehand
  * Trained on known data
  * Tested on unknown data
  * Useful for feature recognition, or identification
  * **3-layer architecture**:
    * Input layer
    * Hidden *(transform)* layer
      * Neurons here **cannot be observed** 
    * Output layer
  * **How does it work?**:
    * One weight per input, and only one output ($$O = g(W\cdot I)$$)
    * Achieves classification by
      * Reducing the difference between the actual and desired outputs
        * Recursively adding and subtracting small adjustments in weights
    * Linearly separable
      * In $n$-dimensional space, two groups are linearly separable if they can be separated by an $n-1$ dimensional hyperplane:
        * $$x_{1}w_{1} + x_{2}w_{2} - \theta \leq 0$$ or $$x_{1}w_{1} + x_{2}w_{2} - \theta \gt 0$$
    * A single Perceptron can only learn linearly separable functions, such as Boolean functions like **AND**, **OR**
    * First step: Initialise the perceptron
      * Assign weights, threshold with random values
    * Second step: Activate
      * Apply input and desired output, and compute the actual output at iteration **p**.
    * Third step: Update the weights
    * Fourth step: Increase **p** by 1, go back to step two and **repeat the process until convergence**.
  * Summation can be carried out by $$v_{j} = \sum\limits_{i=0}^{n} w_{i}\cdot x_{i}$$
  * Non-linear activation function ($\varphi$) is given by $$\varphi(v_{j}) = \frac{1}{1+exp(-v_{j})}$$
  * Backpropagation: the **contribution** of each weight to the output is calculated
    * Weights are adjusted to be *better* next time using the **delta rule**
      * Delta rule: $$w_{ij}(t+1) = w_{ij}(t) + \eta\delta_jy_i$$
      * For output nodes: $$\delta_k = y_k[1-y_k]\bullet(t_k - y_k)$$
      * For hidden nodes: $$\delta_j = y_j[1-y_j]\bullet\sum\limits_{k=1}^{K}[\delta_kw_{kj}]$$

* **How many layers?**:

  * Depends on the problem
  * Two hidden layers are sufficient to solve any problem theoretically
  * But, *more features* implies that more layers may be better

  <img src="https://i.redd.it/5193db0avbey.jpg" width="55%">

#### Decision boundaries

* In simple cases, divide the feature space by constructing a **hyperplane** across it.
* Discriminant function: returns differing values on opposite sides of a straight line
* Problems which can be thus classified as linearly separable

![perceptron-dsurf](https://image.slidesharecdn.com/lect4-uwa-160515043856/95/artificial-neural-network-lect4-single-layer-perceptron-classifiers-15-638.jpg?cb=1463287198)

#### Problems with neural networks

* Lots of parameters to set (hidden nodes, for example)
* Overfitting (over-training)
* Long training times
* Lots of data to collect for the neural network output to be '*acceptable*'

#### Parameter settings

* How many layers?
* How many neurons in the hidden layer?
* If too many neurons, then more training time is required
* Learning rate? $\alpha = 0.1$
* Parameters should only be 'tuned' using information derived from the training or validation set (**not the test set**)

#### Training time

* How many epochs?
  * Stop if the error does not improve
  * Stop if the rate of improvement falls below a defined threshold
  * Stop if the error reaches a defined threshold
  * Stop after $n$ epochs

#### Overfitting

* With sufficient nodes, a training set can be classified to 100%
  * But, this may have **poor generalisation ability**.
* The solution to this is to **cross-validate** with a validation set (usually 30% of data records)
  * Validation set error is checked for each epoch
  * Stop the training process when or if the error increases





