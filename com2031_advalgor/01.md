# Advanced Algorithms
## Introduction
Recap: An algorithm:
* Is an abstract procedure on how to calculate something
* Exists independently of implementation (operating system, programming language)
* Algorithms have associated complexities, notably time and space

Time complexity is a property of the algorithm itself and not the implementation.

There is no general way to find an algorithm for a given problem. Solving a problem requires careful consideration, and is usually tackled in three steps:
1. Is there even an algorithm at all that could solve this problem? Some problems may only be solved by a **brute-force** approach
2. Is the algorithm *right*? Does it solve the problem in a finite time, or does it take an infinite amount of time to solve?
3. Can the algorithm be improved and its overall computational complexity be reduced? Or is there a more efficient algorithm?

## Examples of problems

**_Sequence Alignment Problem_**
* Spellcheck
* Similarity metric - distance between strings (alphabetically)
* A penalty cost for mismatched letters and gaps in strings: lowest cost = better spelled word for example

**_Closest Pair of Points_**
* Goal: Find a pair of points with the smallest distance between them
* Metric for shortest distance would be **Euclidean distance**

**_Shortest Path (Dijkstra)_**
* Already covered

**_Graph k-Colouring problem_**
* Connected graph of vertices
* Any two adjacent vertices must have a differing colour
* Can all vertices satisfy this problem?

**_Knapsack problem_**
* Already covered

**_GCD problem_**
* Given two integers `a` and `b`, find the **greatest common divisor** between them, `d`.
* Example: `gcd(12,18)` is equal to 6
* Example 2: `gcd(27,13)` is equal to 1, since 27 and 13 are *co-prime*.

## Divide and Conquer Algorithms
A **divide and conquer** algorithm is a way of solving a problem on a large dataset by:
* Breaking up the dataset into smaller parts
* Solve each part **recursively**
* Combine part-solved solutions into one overall solution.

Examples of these algorithms covered in *COM1029* include:
* Quick sort
* Binary search

### Quick sort
Time complexity:
* Best-case: `O(n log n)` **logarithmic**
* Average-case: `O(n log n)` **logarithmic**
* Worst-case: `O(n^2)` **quadratic**

Quick sort usually incurs `log2(n)` repetitions of list divisions, hence the average-case logarithmic time complexity. However, if a **bad choice of pivot** is used, then there may be only one element in a partition (as the list is not split evenly). In this case, the `partition()` subroutine in the implementation is called `n` times, meaning that the worst-case time complexity here is quadratic.

It is common to have worst-case performance for quick sort when the first element is used as pivot, and when the list is already sorted. Hence, it is often preferred to choose a **random element** of the data array to use as the pivot, such that good results are given with high probability rates - even if the list is already sorted or nearly sorted.

### Merge sort
Merge sort works in the following way:
* Input list with `n` elements
 * Split input into 2 lists of similar size (ideally same size)
 * Recursively sort the two sublists by repeating the algorithm
 * Merge sublists to one list using the **combination step**

**_The Combination Step_**
* Use a temporary array
* Two pointers starting at the first element in both sublists
* Insert smallest of two elements into the new array *(element is consumed in old array)*
* Move smallest element pointer
* Repeat until done

### Counting inversions problem
This is a nice way of determining similarity between two pieces of data, such as two strings.

For example:
A music site tries to match your song preferences with others:
* You rank n songs
* A music site consults a database to find people with similar music tastes
* 'Similar' in this sense meaning the ranks of songs are close to each other

So, for songs A,B,C,D,E:
* Reference rank of 1,2,3...,n
* Second comparison rank of a(1),a(2),a(3)...,a(n)
* Songs i and j are **inverted** if i < j **but** a(i) > a(n)

Count the number of inversions to determine similarity.

Input: List S with n elements
*Divide*: Split input list into two sublists of similar size
*Conquer*: Recursively count inversions in each sublist.
*Combine*: Count inversions where a(i) and a(j) are in different sublists. Return the total sum of inversions.

* Time complexity of `O(n)` if both sublists are sorted, and `O(n log n)` if sorting the sublists is necessary.

### Summary of Divide and Conquer
Divide and conquer relies on:
* Splitting a computational problem into smaller subproblems, that can be solved independently
* By continued splitting, reach a simple base case that is trivial to solve

Note that:
* Finding suitable subproblems is not easy
* Combining subproblem solutions is also not easy
