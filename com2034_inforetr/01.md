# Information Retrieval
## Introduction

Information Retrieval, or 'IR' for short, refers to obtaining information resources that are relevant and specific to an information requirement from a collection of sources. Searches for relevant information can be based on full-text searching, or other content-based indexing. In itself, information retrieval is a science; it is an umbrella with regards to many different methods of searching for information in a document, *sets* of documents, and even associated metadata that are linked to documents.

* Web search engines are the most commonly identifiable applications that utilise IR.

### Why is this useful?
Information Retrieval allows for systemic categorisation of resources, and for efficient categorisation of data and documents.

*Peter Morville* defined the term "Findability" in 2005 to mean:
> The ability to identify an appropriate Web site and navigate the pages of the site to discover and retrieve relevant information resources.

Findability falls under the domain of **search engine optimisation (SEO)**, **internet marketing** and **data analytics**.

There is simply too much information in existence, especially on the Internet, to be able to process in an efficient manner. In addition, with respect to social media and inter-connectivity with online services, the rate of data generation has increased exponentially over the last 10 years.

* 90% of the world's data has been generated over the last two years.

* The volume of data generated by Google's self-autonomous car is estimated to be `1GB/s` per vehicle per second.

* Eric Schmidt, of Google, Inc, said this in 2010:
> The estimated size of all information created from the dawn of civilisation to 2003 is around 5 exabytes. At Google, we process that volume of data every 2-3 days.

 *NB: 1 exabyte = 1 million terabytes*

So, it's obvious that there needs to be huge improvements in not only network transmission capabilities, but storage and retrieval systems to be able to manage this data appropriately.

### The searchable web
Search engines, such as Google, DuckDuckGo and Bing, only cover a small proportion of the web.

* The **deep web** refers to information that is not directly indexable by web crawlers. For example, this may be private data beind a password-protected portal.
* The **deep web** is estimated to be around 400-500x the size of the **searchable web**.
* Google's page index volume has not changed significantly in recent years (~25bn pages), despite exponential growth in data generation
* Google biases results in terms of search order based on **Google PageRank**, their primary searching and categorisation algorithm, as well as website reputation and advertising campaigns.

Search algorithms and techniques do not work most efficiently at all levels of scale!
* Some are better suited to small datasets, others are suited to large datasets.
